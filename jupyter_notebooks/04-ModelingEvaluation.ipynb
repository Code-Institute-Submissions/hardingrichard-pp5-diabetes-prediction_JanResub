{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Predicting Outcome for Diabetes**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To build a Support Vector Machine Learning model in order to predict whether a patient is Diabetic or Non-Diabetic.\n",
        "* Training the Machine Learning Model.\n",
        "* Evaluate the accuracy score of the Machine Learning model.\n",
        "* We will be answering Business Requirements 2 & 3:\n",
        "    * 2 - The client requires a machine learning tool that their healthcare practitioners can use to identify whether a patient has diabetes.\n",
        "    * 3 - The client expects an accuracy score of 75% or higher in predicting the outcome of diabetes.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/diabetes.csv\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* x_train dataset\n",
        "* y_train dataset\n",
        "* Support Vector Machine Pipeline\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This Notebook falls under the CRISP-DM of Modeling and Evaluation. There is also a small part Data preparation involved from previous notebook.\n",
        "* A Machine Learning Model will be created using a SVM model which we will then evaluate the accuracy score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As the notebooks are stored in the subfolder 'jupyter_notebooks' we therefore, when running the notebook in the editor, need to change the working directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5-diabetes-prediction/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5-diabetes-prediction'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing the Libraries"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Here we import the libraries/dependencies that will be used for creation of the Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Loading the Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will load the Diabetes Dataset along with the cleaned data from previous for use"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diabetes Source Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(f\"outputs/datasets/collection/diabetes.csv\")\n",
        "df.head(15)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Dataset Collection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will run through the steps we took in the Feature Engineering notebook to get the dataset ready for the train test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "(768, 9)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(f\"inputs/datasets/raw/diabetes.csv\")\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    500\n",
              "1    268\n",
              "Name: Outcome, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Processing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Going through the same processes we took in the Feature Engineering notebook to pre-process the data ready for train test split. Refer back to 03-FeatureEngineering.ipynb to see the processes we took in detail."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will begin by dropping the Outcome column to separate the feature variables from the target variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0              6      148             72             35        0  33.6   \n",
            "1              1       85             66             29        0  26.6   \n",
            "2              8      183             64              0        0  23.3   \n",
            "3              1       89             66             23       94  28.1   \n",
            "4              0      137             40             35      168  43.1   \n",
            "..           ...      ...            ...            ...      ...   ...   \n",
            "763           10      101             76             48      180  32.9   \n",
            "764            2      122             70             27        0  36.8   \n",
            "765            5      121             72             23      112  26.2   \n",
            "766            1      126             60              0        0  30.1   \n",
            "767            1       93             70             31        0  30.4   \n",
            "\n",
            "     DiabetesPedigreeFunction  Age  \n",
            "0                       0.627   50  \n",
            "1                       0.351   31  \n",
            "2                       0.672   32  \n",
            "3                       0.167   21  \n",
            "4                       2.288   33  \n",
            "..                        ...  ...  \n",
            "763                     0.171   63  \n",
            "764                     0.340   27  \n",
            "765                     0.245   30  \n",
            "766                     0.349   47  \n",
            "767                     0.315   23  \n",
            "\n",
            "[768 rows x 8 columns]\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "763    0\n",
            "764    0\n",
            "765    0\n",
            "766    1\n",
            "767    0\n",
            "Name: Outcome, Length: 768, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x = df.drop(columns = 'Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we re-visit the process of standardising the data. Using the functions StandardScaler(), fit() and transform()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_scaler.fit(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n"
          ]
        }
      ],
      "source": [
        "stnd_data = df_scaler.transform(x)\n",
        "print(stnd_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n",
            "0      1\n",
            "1      0\n",
            "2      1\n",
            "3      0\n",
            "4      1\n",
            "      ..\n",
            "763    0\n",
            "764    0\n",
            "765    0\n",
            "766    1\n",
            "767    0\n",
            "Name: Outcome, Length: 768, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x = stnd_data\n",
        "y = df['Outcome']\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Having processed the data we can now move onto the Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Like in the previous notebook we will then need to carry out a Train Test Split in order to train our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Records: (768, 8) \n",
            "Train set: (614, 8) \n",
            "Test set: (154, 8)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=2)\n",
        "print(f\"Total Records: {x.shape} \\nTrain set: {x_train.shape} \\nTest set: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will now need to create the pipeline for the Support Vector Machine model which we will be training and using to predict the Outcome of Diabetes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Support Vector Machine pipeline for predicting output of Diabetes\n",
        "class SVM_pipeline():\n",
        "\n",
        "    # Initiates the hyperparameters\n",
        "    def __init__(self, tuning_parameter, iteration_no, lambda_parameter):\n",
        "        self.tuning_parameter = tuning_parameter\n",
        "        self.iteration_no = iteration_no\n",
        "        self.lambda_parameter = lambda_parameter\n",
        "\n",
        "    # Fits the diabetes dataset to the SVM classifier model\n",
        "    def fit(self, x, y):\n",
        "        # M refers to the No. of data points (rows) and Y refers to No. of input features (columns)\n",
        "        self.m, self.n = x.shape\n",
        "\n",
        "        # Initiate weight and bias values\n",
        "        self.w = np.zeros(self.n)\n",
        "        self.b = 0\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        # Optimisation Algorithm\n",
        "        for i in range(self.iteration_no):\n",
        "            self.update_weight_value()\n",
        "    \n",
        "    # Encoding the label\n",
        "    def update_weight_value(self):\n",
        "        label_y = np.where(self.y <= 0, -1, 1)\n",
        "\n",
        "        # Conditions for the gradients (dw, db)\n",
        "        for index, x_i in enumerate(self.x):\n",
        "            constraint = label_y[index] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "\n",
        "            if (constraint == True):\n",
        "                dw = 2 * self.lambda_parameter * self.w\n",
        "                db = 0\n",
        "            \n",
        "            else:\n",
        "                dw = 2 * self.lambda_parameter * self.w - np.dot(x_i, label_y[index])\n",
        "                db = label_y[index]\n",
        "                \n",
        "            # Formula used for updating weight and bias values\n",
        "            self.w = self.w - self.tuning_parameter * dw\n",
        "            self.b = self.b - self.tuning_parameter * db\n",
        "    \n",
        "    # Predicts the Outcome label when using an input value\n",
        "    def diabetes_prediction(self, x):\n",
        "        result = np.dot(x, self.w) - self.b\n",
        "        label_prediction = np.sign(result)\n",
        "        predicted_outcome = np.where(label_prediction <= -1, 0, 1)\n",
        "\n",
        "        return predicted_outcome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now we will begin training the SVM classifier model which we just created using the Train Test Split in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_SVM = SVM_pipeline(tuning_parameter=0.001, iteration_no=1000, lambda_parameter=0.01)\n",
        "\n",
        "classifier_SVM.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_predict = classifier_SVM.diabetes_prediction(x_train)\n",
        "x_test_predict = classifier_SVM.diabetes_prediction(x_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Set Accuracy Score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now we will gather an accuracy score for the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset Accuracy Score:  0.7866449511400652\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = accuracy_score(x_train_predict, y_train)\n",
        "print('Train dataset Accuracy Score: ', train_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As we can see the Accuracy score is showing at 0.786 which is above the Business Requirement 3 of needing a score of at least 0.75. If the score was below this then it would be deemed a fail. However, as we are above the 0.75 minimum requirement this can be considered a success."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Set Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test dataset Accuracy Score:  0.7727272727272727\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = accuracy_score(x_test_predict, y_test)\n",
        "print('Test dataset Accuracy Score: ', test_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As we can see the Accuracy score is showing at 0.772 which is just above the Business Requirement 3 of needing a score of at least 0.75. If the score was below this then it would be deemed a fail. However, as we have met the 0.75 minimum requirement this can be considered a success.\n",
        "\n",
        "* As the training and test data has output similar Accuracy Scores it is a good indication that the model is not overtrained. If the accuracy score was high in the training data and the test data was low then this would be a signal that the model is overfitted.\n",
        "\n",
        "* Unfortunately one of the limitations we have is due to the low size of the dataset, it is difficult to get a high accuracy as there isn't a lot of training data for the model to then use with the test data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we will calculate the confusion matrix to evaluate the performance of the SVM model on the training dataset\n",
        "* The confusion matrix is a table which shows the number of correct and incorrect predictions made by the Support Vector Machine model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix Train Output:\n",
            "True Positive Predictions: 359\n",
            "False Negative Predictions: 41\n",
            "False Positive Predictions: 90\n",
            "True Negative Predictions: 124\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix_train = confusion_matrix(y_train, x_train_predict)\n",
        "\n",
        "# Custom template string for the confusion matrix output for clearer readability\n",
        "train_template = (\n",
        "    \"Confusion Matrix Train Output:\\n\"\n",
        "    \"True Positive Predictions: {}\\n\"\n",
        "    \"False Negative Predictions: {}\\n\"\n",
        "    \"False Positive Predictions: {}\\n\"\n",
        "    \"True Negative Predictions: {}\"\n",
        "    )\n",
        "\n",
        "# Inserts the values from the confusion matrix into the custom template\n",
        "train_output_string = train_template.format(\n",
        "    confusion_matrix_train[0][0],\n",
        "    confusion_matrix_train[0][1],\n",
        "    confusion_matrix_train[1][0],\n",
        "    confusion_matrix_train[1][1]\n",
        "    )\n",
        "\n",
        "print(train_output_string)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix Test Output:\n",
            "True Positive Predictions: 91\n",
            "False Negative Predictions: 9\n",
            "False Positive Predictions: 26\n",
            "True Negative Predictions: 28\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix_train = confusion_matrix(y_test, x_test_predict)\n",
        "\n",
        "# Custom template string for the confusion matrix output for clearer readability\n",
        "test_template = (\n",
        "    \"Confusion Matrix Test Output:\\n\"\n",
        "    \"True Positive Predictions: {}\\n\"\n",
        "    \"False Negative Predictions: {}\\n\"\n",
        "    \"False Positive Predictions: {}\\n\"\n",
        "    \"True Negative Predictions: {}\"\n",
        "    )\n",
        "\n",
        "# Inserts the values from the confusion matrix into the custom template\n",
        "test_output_string = test_template.format(\n",
        "    confusion_matrix_train[0][0],\n",
        "    confusion_matrix_train[0][1],\n",
        "    confusion_matrix_train[1][0],\n",
        "    confusion_matrix_train[1][1]\n",
        "    )\n",
        "\n",
        "print(test_output_string)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The true positive value represents the number of times the model correctly predicted the Diabetic outcome (1).\n",
        "\n",
        "* The false negative value represents the number of times the model incorrectly predicted a Non-Diabetic outcome(0) for the dataset values that was actually Diabetic (1).\n",
        "\n",
        "* The false positive value represents the number of times the model incorrectly predicted the Diabetic outcome (1) for the dataset values that was actually Non-Diabetic (0). \n",
        "\n",
        "* The true negative value represents the number of times the model correctly predicted the Non-Diabetic outcome (0).\n",
        "\n",
        "* As we can see above, the confusion matrix shows us that the model is predicting a higher number of true positive and true negative predictions compared to that of the false positive and false negative predictions. This indicates to us that the model is performing well on both the train and test datasets."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predictive Power Score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classification Report"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we will use the classification_report function using the sklearn library to generate a report that includes various evaluation metrics such as precision, recall and the F1 score for the performance of the Support Vector Machine model on the training and test sets.This will allow us to assess the overall performance and **Predictive Power Score** to identify areas for improvement."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85       400\n",
            "           1       0.75      0.58      0.65       214\n",
            "\n",
            "    accuracy                           0.79       614\n",
            "   macro avg       0.78      0.74      0.75       614\n",
            "weighted avg       0.78      0.79      0.78       614\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_report = classification_report(y_train, x_train_predict)\n",
        "print(train_report)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84       100\n",
            "           1       0.76      0.52      0.62        54\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.77      0.71      0.73       154\n",
            "weighted avg       0.77      0.77      0.76       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_report = classification_report(y_test, x_test_predict)\n",
        "print(test_report)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The classification report provides a detailed breakdown of the evaluation metrics for the output of \"Diabetic\" (1) and \"Non-Diabetic\" (0) in both the training and test datasets.\n",
        "\n",
        "* Let's now asses what each score means:\n",
        "    * Precision: Precision is the number of true Diabetic predictions made by the model, divided by the total number of Diabetic predictions made by the model. It measures the proportion of Diabetic predictions that are actually correct.\n",
        "    * Recall: Recall is the number of true Diabetic predictions made by the model, divided by the total number of actual Diabetic cases in the data. It measures the proportion of actual Diabetic cases that were correctly predicted by the model.\n",
        "    * f1-score: The f1-score is the harmonic mean of precision and recall. It is a balance between precision and recall and reaches its best value at 1.\n",
        "    * Support: Support is the number of samples of the true response that lies in the outcome of Diabetic(1) and Non-Diabetic(0).\n",
        "\n",
        "\n",
        "* As we can see the report also returns the overall accuracy score  which is the proportion of correct predictions and confirms what we saw further above. From this, we can see that the model is performing well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the Predictive Outcome"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now we will perform a manual test of a dataset to give us a predictive Outcome ready for use.\n",
        "\n",
        "* We will take a randomised row of data from the original data set to predict the outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random row of data from source dataset\n",
        "manual_input = (1,97,66,15,140,23.2,0.487,22)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Then we need to convert the data to a numpy array and reshape it for only one record to be used rather than the whole dataset (768 records)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "manual_input_nparray = np.asarray(manual_input)\n",
        "manual_input_shaped = manual_input_nparray.reshape(1, -1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we need to standardise the manually input data. The reason we do this is because the model was trained on a standardised set of data so if we use the raw data then we will get an inaccurate prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.84488505 -0.74783062 -0.16054575 -0.3472913   0.52271486 -1.11594738\n",
            "   0.04567536 -0.95646168]]\n"
          ]
        }
      ],
      "source": [
        "stnd_manual_input = df_scaler.transform(manual_input_shaped)\n",
        "print(stnd_manual_input)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Last we will create a variable to make a prediction using our trained model for the target Outcome of the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "predict = classifier_SVM.diabetes_prediction(stnd_manual_input)\n",
        "print(predict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Having an output of '0' tells us that the model predicted correctly and from the data the person is non-diabetic. However, having an output of '0' isn't descriptive or clear for the end user so we will create an if statement to print whether the person is shown to likely have diabetes or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the data entered. This person does not show signs of being diabetic.\n"
          ]
        }
      ],
      "source": [
        "if (predict[0] == 0):\n",
        "    print('Based on the data entered. This person does not show signs of being diabetic.')\n",
        "else: \n",
        "    print('Based on the data entered. This person shows signs of being diabetic.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As we can see we have a user friendly output message. Although we have a high confidence in the model, it isn't 100% accurate so we cannot guarantee that the person is either diabetic or non-diabetic so further review by the medical worker may be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will be be pushing the following files to the repository\n",
        "    * Train set data\n",
        "    * Test set data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "version = 'v1.0'\n",
        "file_path = f\"outputs/svm_pipeline/predict_diabetes/{version}\"\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>-0.059293</td>\n",
              "      <td>-3.572597</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.051710</td>\n",
              "      <td>-0.999286</td>\n",
              "      <td>-0.786286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>-0.497453</td>\n",
              "      <td>0.046245</td>\n",
              "      <td>0.719086</td>\n",
              "      <td>-0.102454</td>\n",
              "      <td>-0.151361</td>\n",
              "      <td>-1.056668</td>\n",
              "      <td>0.319855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>2.131507</td>\n",
              "      <td>-0.470732</td>\n",
              "      <td>0.154533</td>\n",
              "      <td>6.652839</td>\n",
              "      <td>-0.240205</td>\n",
              "      <td>-0.223115</td>\n",
              "      <td>2.191785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.547919</td>\n",
              "      <td>-0.497453</td>\n",
              "      <td>0.563223</td>\n",
              "      <td>1.534551</td>\n",
              "      <td>0.965543</td>\n",
              "      <td>0.216705</td>\n",
              "      <td>0.722182</td>\n",
              "      <td>-0.360847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>1.849832</td>\n",
              "      <td>-0.160546</td>\n",
              "      <td>1.158182</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>1.270134</td>\n",
              "      <td>4.291962</td>\n",
              "      <td>-0.701198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -1.141852 -0.059293 -3.572597 -1.288212 -0.692891  0.051710 -0.999286   \n",
              "1  0.639947 -0.497453  0.046245  0.719086 -0.102454 -0.151361 -1.056668   \n",
              "2 -0.844885  2.131507 -0.470732  0.154533  6.652839 -0.240205 -0.223115   \n",
              "3 -0.547919 -0.497453  0.563223  1.534551  0.965543  0.216705  0.722182   \n",
              "4 -1.141852  1.849832 -0.160546  1.158182 -0.692891  1.270134  4.291962   \n",
              "\n",
              "          7  \n",
              "0 -0.786286  \n",
              "1  0.319855  \n",
              "2  2.191785  \n",
              "3 -0.360847  \n",
              "4 -0.701198  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(x_train).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pd.DataFrame(x_train).to_csv(f\"{file_path}/x_train.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outcome\n",
              "619        1\n",
              "329        0\n",
              "13         1\n",
              "476        1\n",
              "45         1"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(y_train).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(y_train).to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Test data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.250952</td>\n",
              "      <td>-0.466156</td>\n",
              "      <td>0.149641</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.785957</td>\n",
              "      <td>-0.799958</td>\n",
              "      <td>-0.531023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.250952</td>\n",
              "      <td>-0.247076</td>\n",
              "      <td>-1.297896</td>\n",
              "      <td>-0.472747</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.217483</td>\n",
              "      <td>-1.002306</td>\n",
              "      <td>-0.956462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>0.817027</td>\n",
              "      <td>0.459827</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.216705</td>\n",
              "      <td>-0.766737</td>\n",
              "      <td>2.702312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.250952</td>\n",
              "      <td>1.536861</td>\n",
              "      <td>-0.263941</td>\n",
              "      <td>1.032726</td>\n",
              "      <td>1.260761</td>\n",
              "      <td>0.318240</td>\n",
              "      <td>-0.349960</td>\n",
              "      <td>-0.275760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.250952</td>\n",
              "      <td>-1.154694</td>\n",
              "      <td>0.149641</td>\n",
              "      <td>0.719086</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.660922</td>\n",
              "      <td>-0.618751</td>\n",
              "      <td>-0.445935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.250952 -0.466156  0.149641 -1.288212 -0.692891 -0.785957 -0.799958   \n",
              "1 -0.250952 -0.247076 -1.297896 -0.472747 -0.692891 -1.217483 -1.002306   \n",
              "2  0.342981  0.817027  0.459827 -1.288212 -0.692891  0.216705 -0.766737   \n",
              "3 -0.250952  1.536861 -0.263941  1.032726  1.260761  0.318240 -0.349960   \n",
              "4 -0.250952 -1.154694  0.149641  0.719086 -0.692891  0.660922 -0.618751   \n",
              "\n",
              "          7  \n",
              "0 -0.531023  \n",
              "1 -0.956462  \n",
              "2  2.702312  \n",
              "3 -0.275760  \n",
              "4 -0.445935  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(x_test).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(x_test).to_csv(f\"{file_path}/x_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outcome\n",
              "615        0\n",
              "80         0\n",
              "148        0\n",
              "132        1\n",
              "501        0"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(y_test).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(y_test).to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We run the code below to save the trained model in our repository for use in the Streamlit dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['outputs/svm_pipeline/predict_diabetes/v1.0/classifier_SVM.pkl']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(value=classifier_SVM, filename=f\"{file_path}/classifier_SVM.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Saving the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'outputs/svm_pipeline/predict_diabetes/v1.0/trained_svm.sav'\n",
        "pickle.dump(classifier_SVM, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_svm_model = pickle.load(open('outputs/svm_pipeline/predict_diabetes/v1.0/trained_svm.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.84488505 -0.74783062 -0.16054575 -0.3472913   0.52271486 -1.11594738\n",
            "   0.04567536 -0.95646168]]\n",
            "[0]\n",
            "Based on the data entered. This person does not show signs of being diabetic.\n"
          ]
        }
      ],
      "source": [
        "manual_input = (1,97,66,15,140,23.2,0.487,22)\n",
        "\n",
        "manual_input_nparray = np.asarray(manual_input)\n",
        "manual_input_shaped = manual_input_nparray.reshape(1, -1)\n",
        "\n",
        "stnd_manual_input = df_scaler.transform(manual_input_shaped)\n",
        "print(stnd_manual_input)\n",
        "\n",
        "predict = load_svm_model.diabetes_prediction(stnd_manual_input)\n",
        "print(predict)\n",
        "\n",
        "if (predict[0] == 0):\n",
        "    print('Based on the data entered. This person does not show signs of being diabetic.')\n",
        "else: \n",
        "    print('Based on the data entered. This person shows signs of being diabetic.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
